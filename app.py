import streamlit as st
import requests
import json
import time
import os
import re
import shutil
import zipfile
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from PIL import Image
from google import genai
from google.genai import types

# [NEW] ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from pydub import AudioSegment
from pydub.silence import detect_silence

# [NEW] ë™ì˜ìƒ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° íš¨ê³¼ ì¶”ê°€
try:
    # VideoFileClip, concatenate_videoclips ì¶”ê°€ (ì˜ìƒ ë³‘í•©ìš©)
    from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, VideoFileClip, concatenate_videoclips
    import numpy as np 
except ImportError:
    st.error("âš ï¸ 'moviepy' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì— 'pip install moviepy numpy'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ì—´ì •í”¼ë”” AI ìœ íŠœë¸Œ ëŒ€ë³¸ êµ¬ì¡° ë¶„ì„ê¸° (Pro)", layout="wide", page_icon="ğŸ¬")

# íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
BASE_PATH = "./web_result_files"
IMAGE_OUTPUT_DIR = os.path.join(BASE_PATH, "output_images")
AUDIO_OUTPUT_DIR = os.path.join(BASE_PATH, "output_audio")
VIDEO_OUTPUT_DIR = os.path.join(BASE_PATH, "output_video") 

# í…ìŠ¤íŠ¸ ëª¨ë¸ ì„¤ì •
GEMINI_TEXT_MODEL_NAME = "gemini-2.5-pro" 

# [ê¸°ë³¸ê°’] ë¬¸ì„œì— ëª…ì‹œëœ ì •í™•í•œ í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ
DEFAULT_SUPERTONE_URL = "https://supertoneapi.com"
DEFAULT_VOICE_ID = "ff700760946618e1dcf7bd" 

# ==========================================
# [í•¨ìˆ˜] 0. TTSìš© í…ìŠ¤íŠ¸ ì •ê·œí™” (ìˆ«ì/ê¸°í˜¸ -> í•œê¸€)
# ==========================================
def num_to_kor(num_str):
    """ìˆ«ì ë¬¸ìì—´ì„ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: 1,500 -> ì²œì˜¤ë°±)"""
    try:
        num_str = num_str.replace(',', '')
        if not num_str.isdigit(): return num_str
        
        num = int(num_str)
        if num == 0: return "ì˜"
        
        units = ['', 'ì‹­', 'ë°±', 'ì²œ']
        big_units = ['', 'ë§Œ', 'ì–µ', 'ì¡°', 'ê²½']
        num_chars = ['', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']
        
        result = []
        big_idx = 0
        
        while num > 0:
            small_part = num % 10000
            if small_part > 0:
                small_res = []
                small_idx = 0
                while small_part > 0:
                    digit = small_part % 10
                    if digit > 0:
                        unit = units[small_idx]
                        char = num_chars[digit]
                        if digit == 1 and small_idx > 0:
                            char = ""
                        small_res.append(char + unit)
                    small_part //= 10
                    small_idx += 1
                result.append("".join(reversed(small_res)) + big_units[big_idx])
            num //= 10000
            big_idx += 1
            
        return "".join(reversed(result))
    except:
        return num_str

def normalize_text_for_tts(text):
    """TTS ë°œìŒì„ ìœ„í•´ íŠ¹ìˆ˜ë¬¸ìì™€ ìˆ«ìë¥¼ í•œê¸€ë¡œ ë³€í™˜"""
    text = text.replace("%", " í¼ì„¼íŠ¸")
    
    def replace_decimal(match):
        return f"{match.group(1)} ì  {match.group(2)}"
    text = re.sub(r'(\d+)\.(\d+)', replace_decimal, text)

    def replace_number(match):
        return num_to_kor(match.group())
    
    text = re.sub(r'\d+(?:,\d+)*', replace_number, text)
    
    return text

# ==========================================
# [í•¨ìˆ˜] 1. ëŒ€ë³¸ êµ¬ì¡°í™” ë¡œì§
# ==========================================
def generate_structure(client, full_script):
    """Geminië¥¼ ì´ìš©í•´ ëŒ€ë³¸ êµ¬ì¡°í™”"""
    prompt = f"""
    [Role]
    You are a professional YouTube Content Editor and Scriptwriter.

    [Task]
    Analyze the provided transcript (script).
    Restructure the content into a highly detailed, list-style format suitable for a blog post or a new video plan.
      
    [Output Format]
    1. **Video Theme/Title**: (Extract or suggest a catchy title based on the whole script)
    2. **Intro**: (Hook and background, no music) Approve specific channel names, The intro hooks the overall topic (ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ ê°™ì€ ì¸ì‚¬ ê¸ˆì§€)
    3. **Chapter 1** to **Chapter 8**: (Divide the main content into logical sections. Use detailed bullet points for each chapter.)
    4. **Epilogue**: (Conclusion and Subscribe Like Comments that make you anticipate the next specific content)

    [Constraint]
    - Analyze the entire context deeply.
    - Write the output in **Korean**.
    - Make the content rich and detailed.
    - If the original script has a channel name, remove it.

    [Transcript]
    {full_script}
    """
    
    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME,
            contents=prompt
        )
        return response.text
    except Exception as e:
        return f"Error: {e}"

# ==========================================
# [í•¨ìˆ˜] 2. ì„¹ì…˜ë³„ ëŒ€ë³¸ ìƒì„± (ìˆ˜ì • ë²„ì „)
# ==========================================
def generate_section(client, section_title, full_structure, duration_type="fixed", custom_instruction=""):
    # 1. ë¶„ëŸ‰ì— ë”°ë¥¸ ê¸€ììˆ˜ ë° ì§€ì¹¨ ì„¤ì •
    if duration_type == "2min":
        target_chars = "ì•½ 1,000ì (ê³µë°± í¬í•¨)"
        detail_level = "í•µì‹¬ ë‚´ìš© ìœ„ì£¼ë¡œ ëª…í™•í•˜ê²Œ ì „ë‹¬í•˜ë˜, ë„ˆë¬´ ì§§ì§€ ì•Šê²Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤."
    elif duration_type == "3min":
        target_chars = "ì•½ 1,500ì (ê³µë°± í¬í•¨)"
        detail_level = "ì¶©ë¶„í•œ ì˜ˆì‹œì™€ ì„¤ëª…ì„ ê³ë“¤ì—¬ ìƒì„¸í•˜ê²Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤."
    elif duration_type == "4min":
        target_chars = "ì•½ 2,000ì ì´ìƒ (ê³µë°± í¬í•¨)"
        detail_level = "í˜„ë¯¸ê²½ìœ¼ë¡œ ë“¤ì—¬ë‹¤ë³´ë“¯ ì•„ì£¼ ê¹Šì´ ìˆê³  ë””í…Œì¼í•˜ê²Œ ë¬˜ì‚¬í•˜ì‹­ì‹œì˜¤. ì ˆëŒ€ ìš”ì•½í•˜ì§€ ë§ˆì‹­ì‹œì˜¤."
    else: # Intro / Epilogue (Fixed)
        target_chars = "ì•½ 400ë‹¨ì–´ (ì•½ 1,400ì)"
        detail_level = "ì‹œì²­ìë¥¼ ì‚¬ë¡œì¡ëŠ” ê°•ë ¥í•œ í›„í‚¹ê³¼ ì—¬ìš´ì„ ì£¼ëŠ” ë§ˆë¬´ë¦¬ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ì•ˆë…• ì¸ì‚¬ëŠ” í•˜ì§€ ì•ŠëŠ”ë‹¤"

    user_guide_prompt = ""
    if custom_instruction:
        user_guide_prompt = f"""
    [User's Special Direction]
    The user has provided specific instructions for the tone/style. You MUST follow this:
    ğŸ‘‰ "{custom_instruction}"
        """

    prompt = f"""
    [Role]
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ìœ íŠœë¸Œ ë‹¤íë©˜í„°ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤.

    [Task]
    ì „ì²´ ëŒ€ë³¸ êµ¬ì¡° ì¤‘ ì˜¤ì§ **"{section_title}"** ë¶€ë¶„ë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
      
    [Context (Overall Structure)]
    {full_structure}
    {user_guide_prompt}

    [Target Section]
    **{section_title}**

    [Length Constraints]
    - **ëª©í‘œ ë¶„ëŸ‰: {target_chars}** - **ì‘ì„± ì§€ì¹¨:** {detail_level}
      
    [Style Guidelines - ë§¤ìš° ì¤‘ìš”]
    1. 'ìŠµë‹ˆë‹¤' ì²´ë¥¼ ì‚¬ìš©í•˜ê³ , ë‹¤íë©˜í„°ë¦¬ íŠ¹ìœ ì˜ ì§„ì§€í•˜ê³  ëª°ì…ê° ìˆëŠ” ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
    2. ì•ë’¤ ë¬¸ë§¥(ì´ì „ ì±•í„°, ë‹¤ìŒ ì±•í„°)ì„ ê³ ë ¤í•˜ë˜, ì´ íŒŒíŠ¸ì˜ ë‚´ìš©ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.
    3. (ì§€ë¬¸), (íš¨ê³¼ìŒ) ê°™ì€ ì—°ì¶œ ì§€ì‹œì–´ëŠ” ì œì™¸í•˜ê³  **ì˜¤ì§ ë‚˜ë ˆì´ì…˜ ëŒ€ì‚¬ë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
    4. ì„œë‘ì— "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤" ê°™ì€ ì¡ë‹´ì„ í•˜ì§€ ë§ê³  ë°”ë¡œ ëŒ€ë³¸ ë‚´ìš©ì„ ì‹œì‘í•˜ì„¸ìš”.
    5. ì˜ë¬¸ ë³‘ê¸°(ê´„í˜¸)ëŠ” í•˜ì§€ ë§ˆì„¸ìš”. ê¹”ë”í•˜ê²Œ í•œê¸€ë§Œ.
    6. ì‰¼í‘œì™€ ì ‘ì†ì–´ ë“±ì„ ì‚¬ìš©í•˜ì—¬, ë¦¬ë“¬ì´ ìˆì§€ë§Œ ë„ˆë¬´ ëŠê¸°ì§€ ì•ŠëŠ” íë¦„ì„ ë§Œë“¤ ê²ƒ.
    
    # [ìˆ˜ì •ë¨] íë¦„ ëŠê¹€ ë°©ì§€ í•µì‹¬ ì§€ì¹¨ --------------------------
    7. **[ê¸ˆì§€ì‚¬í•­]** ê¸€ì˜ ë§ˆì§€ë§‰ì— "ë‹¤ìŒ ì¥ì—ì„œëŠ”...", "ì´ì–´ì„œ...", "ì´ì œ ~ë¥¼ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤" ê°™ì€ **ì˜ˆê³ ì„± ë©˜íŠ¸ë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.**
    8. **[ê¸ˆì§€ì‚¬í•­]** "ì§€ê¸ˆê¹Œì§€ ~ë¥¼ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤" ê°™ì€ **ì¤‘ê°„ ì •ë¦¬ ë©˜íŠ¸ë„ ì ˆëŒ€ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.**
    9. ì´ í…ìŠ¤íŠ¸ë“¤ì€ ë‚˜ì¤‘ì— í•˜ë‚˜ë¡œ í•©ì³ì§ˆ ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ **ê·¸ëƒ¥ ì„¤ëª…í•˜ë‹¤ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì¥(ë§ˆì¹¨í‘œ)ìœ¼ë¡œ ëë‚´ì‹­ì‹œì˜¤.** ë’·ë‚´ìš©ì€ ë‹¤ìŒ í…ìŠ¤íŠ¸ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ë°›ìŠµë‹ˆë‹¤.
    10. ì±•í„° ë²ˆí˜¸ë‚˜ ì†Œì œëª©ì„ ë³¸ë¬¸ì— ë‹¤ì‹œ ì ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ ë‚´ìš©ë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
    ---------------------------------------------------------

    [Output]
    (ì§€ê¸ˆ ë°”ë¡œ {section_title}ì˜ ì›ê³ ë¥¼ ì‘ì„± ì‹œì‘í•˜ì„¸ìš”)
    """
    
    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME, 
            contents=prompt,
            config=types.GenerateContentConfig(
                max_output_tokens=8192,
                temperature=0.75 
            )
        )
        return response.text
    except Exception as e:
        return f"Error: {e}"

# ==========================================
# [í•¨ìˆ˜] 3. ì´ë¯¸ì§€ ìƒì„± ê´€ë ¨ ë¡œì§
# ==========================================

def init_folders():
    for path in [IMAGE_OUTPUT_DIR, AUDIO_OUTPUT_DIR, VIDEO_OUTPUT_DIR]:
        if not os.path.exists(path):
            os.makedirs(path, exist_ok=True)

def split_script_by_time(script, chars_per_chunk=100):
    temp_sentences = script.replace(".", ".|").replace("?", "?|").replace("!", "!|").split("|")
    chunks = []
    current_chunk = ""
    for sentence in temp_sentences:
        sentence = sentence.strip()
        if not sentence: continue
        if len(current_chunk) + len(sentence) < chars_per_chunk:
            current_chunk += " " + sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk:
        chunks.append(current_chunk.strip())
    return chunks

def make_filename(scene_num, text_chunk):
    clean_line = text_chunk.replace("\n", " ").strip()
    clean_line = re.sub(r'[\\/:*?"<>|]', "", clean_line)
    words = clean_line.split()
    
    if len(words) <= 6:
        summary = " ".join(words)
    else:
        start_part = " ".join(words[:3])
        end_part = " ".join(words[-3:])
        summary = f"{start_part}...{end_part}"
    
    filename = f"S{scene_num:03d}_{summary}.png"
    return filename

# ==========================================
# [ìµœì¢… ìˆ˜ì •ë¨] í•¨ìˆ˜: í”„ë¡¬í”„íŠ¸ ìƒì„± (ì‚¬ìš©ì ì›ë³¸ ìœ ì§€ + ì–¸ì–´ ì„ íƒ ê¸°ëŠ¥)
# ==========================================
def generate_prompt(api_key, index, text_chunk, style_instruction, video_title, genre_mode="info", target_language="Korean"):
    scene_num = index + 1
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_TEXT_MODEL_NAME}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}

    # [ì–¸ì–´ ì„¤ì • ë¡œì§] ì„ íƒëœ ì–¸ì–´ì— ë”°ë¼ ì§€ì¹¨ ìë™ ë³€ê²½
    if target_language == "Korean":
        lang_guide = "í™”ë©´ ì† ê¸€ì”¨ëŠ” **ë¬´ì¡°ê±´ 'í•œê¸€(Korean)'ë¡œ í‘œê¸°**í•˜ì‹­ì‹œì˜¤. (ë‹¤ë¥¸ ì–¸ì–´ ì ˆëŒ€ ê¸ˆì§€)"
        lang_example = "(ì˜ˆ: 'New York' -> 'ë‰´ìš•', 'Tokyo' -> 'ë„ì¿„')"
    elif target_language == "English":
        lang_guide = "í™”ë©´ ì† ê¸€ì”¨ëŠ” **ë¬´ì¡°ê±´ 'ì˜ì–´(English)'ë¡œ í‘œê¸°**í•˜ì‹­ì‹œì˜¤."
        lang_example = "(ì˜ˆ: 'ì„œìš¸' -> 'Seoul', 'ë…ë„' -> 'Dokdo')"
    elif target_language == "Japanese":
        lang_guide = "í™”ë©´ ì† ê¸€ì”¨ëŠ” **ë¬´ì¡°ê±´ 'ì¼ë³¸ì–´(Japanese)'ë¡œ í‘œê¸°**í•˜ì‹­ì‹œì˜¤."
        lang_example = "(ì˜ˆ: 'ì„œìš¸' -> 'ã‚½ã‚¦ãƒ«', 'New York' -> 'ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯')"
    else:
        lang_guide = f"í™”ë©´ ì† ê¸€ì”¨ëŠ” **ë¬´ì¡°ê±´ '{target_language}'ë¡œ í‘œê¸°**í•˜ì‹­ì‹œì˜¤."
        lang_example = ""

    # ---------------------------------------------------------
    # [ëª¨ë“œ 1] ë°ì€ ì •ë³´/ì´ìŠˆ (ì‚¬ìš©ì ì›ë³¸ ìœ ì§€)
    # ---------------------------------------------------------
    if genre_mode == "info":
        full_instruction = f"""
    [ì—­í• ]
    ë‹¹ì‹ ì€ ë³µì¡í•œ ìƒí™©ì„ ì•„ì£¼ ì‰½ê³  ì§ê´€ì ì¸ ê·¸ë¦¼ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” 'ë¹„ì£¼ì–¼ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€'ì´ì 'êµìœ¡ìš© ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´í„°'ì…ë‹ˆë‹¤.

    [ì „ì²´ ì˜ìƒ ì£¼ì œ]
    "{video_title}"

    [ê·¸ë¦¼ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ - ì ˆëŒ€ ì¤€ìˆ˜]
    {style_instruction}
    
    [í•„ìˆ˜ ì—°ì¶œ ì§€ì¹¨]
    1. **ì¡°ëª…(Lighting):** ë¬´ì¡°ê±´ **'ë°ê³  í™”ì‚¬í•œ ì¡°ëª…(High Key Lighting)'**ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ê·¸ë¦¼ìê°€ ì§™ê±°ë‚˜ ì–´ë‘ìš´ ë¶€ë¶„ì€ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
    2. **ìƒ‰ê°(Colors):** ì±„ë„ê°€ ë†’ê³  ì„ ëª…í•œ ìƒ‰ìƒì„ ì‚¬ìš©í•˜ì—¬ ì‹œì¸ì„±ì„ ë†’ì´ì‹­ì‹œì˜¤. (ì¹™ì¹™í•˜ê±°ë‚˜ íšŒìƒ‰ì¡° í†¤ ê¸ˆì§€)
    3. **êµ¬ì„±(Composition):** ì‹œì²­ìê°€ ìƒí™©ì„ í•œëˆˆì— ì´í•´í•  ìˆ˜ ìˆë„ë¡ í”¼ì‚¬ì²´ë¥¼ í™”ë©´ ì¤‘ì•™ì— ëª…í™•í•˜ê²Œ ë°°ì¹˜í•˜ì‹­ì‹œì˜¤.
    4. **ë¶„ìœ„ê¸°(Mood):** êµìœ¡ì ì´ê³ , ì¤‘ë¦½ì ì´ë©°, ì‚°ëœ»í•œ ë¶„ìœ„ê¸°ì—¬ì•¼ í•©ë‹ˆë‹¤. **(ì ˆëŒ€ ìš°ìš¸í•˜ê±°ë‚˜, ë¬´ì„­ê±°ë‚˜, ê¸°ê´´í•œ ëŠë‚Œ ê¸ˆì§€)**
    5. ë¶„í™œí™”ë©´ìœ¼ë¡œ ì—°ì¶œí•˜ì§€ ë§ê³  í•˜ë‚˜ì˜ í™”ë©´ìœ¼ë¡œ ì—°ì¶œí•œë‹¤.
    6. **[í…ìŠ¤íŠ¸ ì–¸ì–´]:** {lang_guide} {lang_example}
    - **[ì ˆëŒ€ ê¸ˆì§€]:** í™”ë©´ì˜ ë„¤ ëª¨ì„œë¦¬(Corners)ë‚˜ ê°€ì¥ìë¦¬(Edges)ì— ê¸€ìë¥¼ ë°°ì¹˜í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ê¸€ìëŠ” ë°˜ë“œì‹œ ì¤‘ì•™ í”¼ì‚¬ì²´ ì£¼ë³€ì—ë§Œ ì—°ì¶œí•˜ì‹­ì‹œì˜¤.
    7. ìºë¦­í„°ì˜ ê°ì •ë„ ëŠê»´ì§„ë‹¤.

    [ì„ë¬´]
    ì œê³µëœ ëŒ€ë³¸ ì¡°ê°(Script Segment)ì„ ë°”íƒ•ìœ¼ë¡œ, ì´ë¯¸ì§€ ìƒì„± AIê°€ ê·¸ë¦´ ìˆ˜ ìˆëŠ” **êµ¬ì²´ì ì¸ ë¬˜ì‚¬ í”„ë¡¬í”„íŠ¸**ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    
    [ì‘ì„± ìš”êµ¬ì‚¬í•­]
    - **ë¶„ëŸ‰:** ìµœì†Œ 5ë¬¸ì¥ ì´ìƒìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ë¬˜ì‚¬.
    - **í¬í•¨ ìš”ì†Œ:**
        - **ìºë¦­í„° í–‰ë™:** ëŒ€ë³¸ì˜ ìƒí™©ì„ ì—°ê¸°í•˜ëŠ” ìºë¦­í„°ì˜ êµ¬ì²´ì ì¸ ë™ì‘.
        - **ë°°ê²½:** ìƒí™©ì„ ì„¤ëª…í•˜ëŠ” ì†Œí’ˆì´ë‚˜ ì¥ì†Œ (ë°°ê²½ì€ ê¹”ë”í•˜ê²Œ).
        - **ì‹œê°ì  ì€ìœ :** ì¶”ìƒì ì¸ ë‚´ìš©ì¼ ê²½ìš°, ì´ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ì‹œê°ì  ì•„ì´ë””ì–´ (ì˜ˆ: ëˆì´ ë‚ ì•„ê°€ëŠ” ëª¨ìŠµ, ê·¸ë˜í”„ê°€ í•˜ë½í•˜ëŠ” ëª¨ìŠµ ë“±).
    
    [ì¶œë ¥ í˜•ì‹]
    - **ë¬´ì¡°ê±´ í•œêµ­ì–´(í•œê¸€)**ë¡œë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    - ë¶€ê°€ì ì¸ ì„¤ëª… ì—†ì´ **ì˜¤ì§ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ë§Œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
        """

    # ---------------------------------------------------------
    # [ëª¨ë“œ 2] ì—­ì‚¬/ë‹¤í (ì‚¬ìš©ì ì›ë³¸ ìœ ì§€ + ì–¸ì–´ ë³€ìˆ˜ ì ìš©)
    # ---------------------------------------------------------
    else: # genre_mode == "history"
        full_instruction = f"""
    [ì—­í• ]
    ë‹¹ì‹ ì€ **ì„¸ê³„ì‚¬ì˜ ê²°ì •ì ì¸ ìˆœê°„ë“¤(í•œêµ­ì‚¬, ì„œì–‘ì‚¬, ë™ì–‘ì‚¬ ë“±)**ì„ í•œêµ­ ì‹œì²­ìì—ê²Œ ì „ë‹¬í•˜ëŠ” 'ì‹œëŒ€ê·¹ ì• ë‹ˆë©”ì´ì…˜ ê°ë…'ì…ë‹ˆë‹¤.

    [ì „ì²´ ì˜ìƒ ì£¼ì œ] "{video_title}"
    [ê·¸ë¦¼ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ - ìœ ì € ì§€ì • (ìµœìš°ì„  ì¤€ìˆ˜)] {style_instruction}
    
    [í•„ìˆ˜ ì—°ì¶œ ì§€ì¹¨]
    1. **[ë§¤ìš° ì¤‘ìš”] ë§¤ì²´(Medium):** ë¬´ì¡°ê±´ **í‰ë©´ì ì¸ '2D ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´ì…˜'** ë˜ëŠ” **'ì…€ ì• ë‹ˆë©”ì´ì…˜'** ìŠ¤íƒ€ì¼ë¡œ í‘œí˜„í•˜ì‹­ì‹œì˜¤. (3D, ì‹¤ì‚¬, ëª¨ë¸ë§ ëŠë‚Œ ì ˆëŒ€ ê¸ˆì§€)
    2. **[ë§¤ìš° ì¤‘ìš”] í…ìŠ¤íŠ¸ í˜„ì§€í™”(Localization):** ë°°ê²½ì´ ì„œì–‘, ì¤‘êµ­, ì¼ë³¸ ë“± ì–´ë””ë“  ìƒê´€ì—†ì´, {lang_guide}
        - **ê¸ˆì§€:** ì§€ì •ëœ ì–¸ì–´ ì™¸ì˜ ë¬¸ì ì‚¬ìš©ì„ ì ˆëŒ€ ê¸ˆì§€í•©ë‹ˆë‹¤.
        - **ì˜ˆì‹œ:** {lang_example}
    3. **[ì†ë„/ê²€ì—´ í•´ê²°] ìˆ˜ìœ„ ì¡°ì ˆ ë° ì€ìœ (Metaphor):** ì „ìŸ, ê³ ë¬¸, ì „ì—¼ë³‘ ë“± ì”ì¸í•œ ë¬˜ì‚¬ëŠ” AI ê²€ì—´ë¡œ ì¸í•´ ì°¨ë‹¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ì§ì ‘ì ì¸ ë¬˜ì‚¬ ëŒ€ì‹  'ì‹œê°ì  ì€ìœ 'ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.**
        - ì˜ˆ) ë‹¨ë‘ëŒ€ ì²˜í˜•/ì „ìŸ -> 'ë–¨ì–´ì§„ ë¶‰ì€ ì¥ë¯¸', 'ë¶‰ê²Œ ë¬¼ë“  ê¹ƒë°œ', 'ë¶€ëŸ¬ì§„ ì¹¼'
        - ì˜ˆ) ì „ì—¼ë³‘/ì£½ìŒ -> 'ê²€ì€ ê¹Œë§ˆê·€ ë–¼', 'ì‹œë“¤ì–´ë²„ë¦° ë‚˜ë¬´', 'êº¼ì§„ ì´›ë¶ˆ', 'í…… ë¹ˆ ê±°ë¦¬'
    4. **[í•µì‹¬] ë‹¤ì–‘í•œ ì¥ì†Œì™€ ì‹œëŒ€ ì—°ì¶œ(Diverse Locations):** ëŒ€ë³¸ì— ë‚˜ì˜¤ëŠ” **íŠ¹ì • ì‹œëŒ€ì™€ ì¥ì†Œì˜ íŠ¹ì§•(ê±´ì¶• ì–‘ì‹, ì˜ìƒ, ìì—°í™˜ê²½)ì„ ì •í™•íˆ í¬ì°©**í•˜ì—¬ ê·¸ë¦¬ì‹­ì‹œì˜¤.
        - ì˜ˆ: ì¤‘ì„¸ ìœ ëŸ½ì˜ ì„±, ì‚°ì—…í˜ëª… ë‹¹ì‹œì˜ ëŸ°ë˜ ê³µì¥, ê³ ëŒ€ ë¡œë§ˆì˜ ì›í˜• ê·¹ì¥, 2ì°¨ ëŒ€ì „ì˜ ì°¸í˜¸, ì¡°ì„ ì˜ ê¶ê¶ ë“± **ë°°ê²½ì„ ë‹¤ì–‘í•˜ê³  ë””í…Œì¼í•˜ê²Œ ì—°ì¶œ**í•˜ì‹­ì‹œì˜¤.
    5. **ìºë¦­í„° ì—°ê¸°(Character Acting):** 2D ìŠ¤í‹±ë§¨ ìºë¦­í„°ì§€ë§Œ, ì‹œëŒ€ì— ë§ëŠ” ì˜ìƒ(íˆ¬êµ¬, ì •ì¥, êµ°ë³µ, í•œë³µ ë“±)ì„ ì…íˆê³  **í¬ë¡œì• ë½ì˜ ê°ì •ì„ ëª¸ì§“ìœ¼ë¡œ ê°•ë ¬í•˜ê²Œ ì—°ì¶œ**í•˜ì‹­ì‹œì˜¤.
    6. **ì¡°ëª…(Lighting):** 2D ì‘í™” ë‚´ì—ì„œ ê·¹ì ì¸ ë¶„ìœ„ê¸°ë¥¼ ë§Œë“œëŠ” **'ì‹œë„¤ë§ˆí‹± ì¡°ëª…'**ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. (ì‹œëŒ€ê·¹ íŠ¹ìœ ì˜ ë¬´ê²ê³  ì›…ì¥í•œ í†¤)
    7. **ìƒ‰ê°(Colors):** **ê¹Šì´ ìˆê³  ì§„í•œ ìƒ‰ì¡°(Rich & Deep Tones)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë³ì§€ ì•Šì€, ë¬µì§í•œ ì—­ì‚¬ ë‹¤íë©˜í„°ë¦¬ì˜ í†¤ì•¤ë§¤ë„ˆë¥¼ ìœ ì§€í•˜ì‹­ì‹œì˜¤.
    8. **êµ¬ì„±(Composition):** ì‹œì²­ìê°€ ìƒí™©ì„ í•œëˆˆì— ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ í”¼ì‚¬ì²´ë¥¼ í™”ë©´ ì¤‘ì•™ì— ë°°ì¹˜í•˜ì‹­ì‹œì˜¤. ë¶„í™œí™”ë©´(Split screen)ì€ ê¸ˆì§€ì…ë‹ˆë‹¤.
    - **[ì ˆëŒ€ ê¸ˆì§€]:** í…ìŠ¤íŠ¸ê°€ í™”ë©´ì˜ ë„¤ ëª¨ì„œë¦¬(Corners)ë‚˜ ê°€ì¥ìë¦¬ì— ë°°ì¹˜ë˜ëŠ” ê²ƒì„ ì ˆëŒ€ ê¸ˆì§€í•©ë‹ˆë‹¤. (ìë§‰ ê³µê°„ í™•ë³´)

    [ì„ë¬´]
    ì œê³µëœ ëŒ€ë³¸ ì¡°ê°(Script Segment)ì„ ë°”íƒ•ìœ¼ë¡œ, ì´ë¯¸ì§€ ìƒì„± AIê°€ ê·¸ë¦´ ìˆ˜ ìˆëŠ” **êµ¬ì²´ì ì¸ ë¬˜ì‚¬ í”„ë¡¬í”„íŠ¸**ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    
    [ì‘ì„± ìš”êµ¬ì‚¬í•­]
    - **ë¶„ëŸ‰:** ìµœì†Œ 5ë¬¸ì¥ ì´ìƒìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ë¬˜ì‚¬.
    - **í¬í•¨ ìš”ì†Œ:**
        - **í…ìŠ¤íŠ¸ ì§€ì‹œ:** (ì¤‘ìš”) ì´ë¯¸ì§€ì— ë“¤ì–´ê°ˆ í…ìŠ¤íŠ¸ë¥¼ ë°˜ë“œì‹œ **'{target_language}'**ë¡œ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
        - **ì•ˆì „í•œ ë¬˜ì‚¬:** ì”ì¸í•œ ì¥ë©´ì€ ì€ìœ ì ìœ¼ë¡œ í‘œí˜„í•˜ì—¬ í•„í„°ë§ì„ í”¼í•˜ì‹­ì‹œì˜¤.
        - **ì‹œëŒ€ì  ë°°ê²½:** ëŒ€ë³¸ì˜ ì‹œëŒ€(ê³ ëŒ€/ì¤‘ì„¸/ê·¼ëŒ€)ì™€ ì¥ì†Œ(ë™ì–‘/ì„œì–‘)ë¥¼ ëª…í™•íˆ ë°˜ì˜í•œ ë°°ê²½ ë¬˜ì‚¬.
        - **ìºë¦­í„° ì—°ê¸°:** ìƒí™©ì— ë”°ë¥¸ ìºë¦­í„°ì˜ í‘œì •ê³¼ ë™ì‘.
    
    [ì¶œë ¥ í˜•ì‹]
    - **ë¬´ì¡°ê±´ í•œêµ­ì–´(í•œê¸€)**ë¡œë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    - ë¶€ê°€ì ì¸ ì„¤ëª… ì—†ì´ **ì˜¤ì§ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ë§Œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
    """
    
    # ê³µí†µ ì‹¤í–‰ ë¡œì§
    payload = {
        "contents": [{"parts": [{"text": f"ì§€ì‹œì‚¬í•­(Instruction):\n{full_instruction}\n\nëŒ€ë³¸ ë‚´ìš©(Script Segment):\n\"{text_chunk}\"\n\nì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê²°ê³¼:"}]}]
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            try:
                prompt = response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
            except:
                prompt = text_chunk
            return (scene_num, prompt)
        elif response.status_code == 429:
            time.sleep(2)
            return (scene_num, f"ì¼ëŸ¬ìŠ¤íŠ¸ ë¬˜ì‚¬: {text_chunk}")
        else:
            return (scene_num, f"Error generating prompt: {response.status_code}")
    except Exception as e:
        return (scene_num, f"Error: {e}")

# ==========================================
# [ìˆ˜ì •ë¨] generate_image: API ì œí•œ(429) ì™„ë²½ ëŒ€ì‘ + ì¬ì‹œë„ ê°•í™”
# ==========================================
def generate_image(client, prompt, filename, output_dir, selected_model_name):
    full_path = os.path.join(output_dir, filename)
    
    # [ìˆ˜ì • 1] ì¬ì‹œë„ íšŸìˆ˜ë¥¼ 10íšŒë¡œ ëŠ˜ë ¤ì„œ ì ˆëŒ€ í¬ê¸°í•˜ì§€ ì•Šê²Œ í•¨
    max_retries = 10
    
    # [ìˆ˜ì • 2] ì•ˆì „ í•„í„° (ê¸°ì¡´ ìœ ì§€)
    safety_settings = [
        types.SafetySetting(
            category="HARM_CATEGORY_DANGEROUS_CONTENT",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_HARASSMENT",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_HATE_SPEECH",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
            threshold="BLOCK_ONLY_HIGH"
        ),
    ]

    for attempt in range(1, max_retries + 1):
        try:
            response = client.models.generate_content(
                model=selected_model_name,
                contents=[prompt],
                config=types.GenerateContentConfig(
                    image_config=types.ImageConfig(aspect_ratio="16:9"),
                    safety_settings=safety_settings 
                )
            )
            
            if response.parts:
                for part in response.parts:
                    if part.inline_data:
                        img_data = part.inline_data.data
                        image = Image.open(BytesIO(img_data))
                        image.save(full_path)
                        return full_path
            
            # ì‘ë‹µì€ ì™”ìœ¼ë‚˜ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° (í•„í„°ë§ ë“±)
            print(f"âš ï¸ [ì‹œë„ {attempt}/{max_retries}] ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ. ì¬ì‹œë„... ({filename})")
            time.sleep(2)
            
        except Exception as e:
            error_msg = str(e)
            # [í•µì‹¬ ìˆ˜ì •] 429 (Too Many Requests) ë˜ëŠ” 429 Resource Exhausted ì—ëŸ¬ ë°œìƒ ì‹œ
            if "429" in error_msg or "ResourceExhausted" in error_msg:
                wait_time = 30  # 30ì´ˆ ë™ì•ˆ ë©ˆì·„ë‹¤ê°€ ë‹¤ì‹œ ì‹œë„ (ë¶„ë‹¹ ì œí•œ ì´ˆê¸°í™” ëŒ€ê¸°)
                print(f"ğŸ›‘ [API ì œí•œ ê°ì§€] {filename} - {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤... (ì‹œë„ {attempt}/{max_retries})")
                time.sleep(wait_time)
            else:
                # ì¼ë°˜ ì—ëŸ¬ëŠ” 5ì´ˆ ëŒ€ê¸°
                print(f"âš ï¸ [ì—ëŸ¬] {error_msg} ({filename}) - 5ì´ˆ ëŒ€ê¸°")
                time.sleep(5)
            
    # [ìµœì¢… ì‹¤íŒ¨]
    print(f"âŒ [ìµœì¢… ì‹¤íŒ¨] {filename} - ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨.")
    return None

def create_zip_buffer(source_dir):
    buffer = BytesIO()
    with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for root, dirs, files in os.walk(source_dir):
            for file in files:
                file_path = os.path.join(root, file)
                zip_file.write(file_path, os.path.basename(file_path))
    buffer.seek(0)
    return buffer

# ==========================================
# [í•¨ìˆ˜] 4. Supertone TTS ë° ì˜¤ë””ì˜¤ í›„ì²˜ë¦¬ (Noise Cut - Micro Fade)
# ==========================================
def check_connection_and_get_voices(api_key, base_url):
    """ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ëª©ì†Œë¦¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    base_url = base_url.rstrip('/')
    url = f"{base_url}/v1/voices"
    headers = {"x-sup-api-key": api_key}
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            voices = []
            if isinstance(data, dict) and "items" in data:
                voices = data["items"]
            elif isinstance(data, list):
                voices = data
            else:
                return False, [], f"ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. (items í‚¤ ì—†ìŒ: {list(data.keys())})"
            
            return True, voices, "âœ… ì—°ê²° ì„±ê³µ!"
            
        elif response.status_code == 401:
            return False, [], "âŒ API Keyê°€ í‹€ë ¸ìŠµë‹ˆë‹¤ (401)"
        elif response.status_code == 404:
            return False, [], f"âŒ ì£¼ì†Œ(URL) ì˜¤ë¥˜ (404). {base_url} ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
        else:
            return False, [], f"âŒ ì„œë²„ ì˜¤ë¥˜ ({response.status_code}): {response.text}"
            
    except Exception as e:
        return False, [], f"âŒ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜: {str(e)}"

def generate_supertone_tts(api_key, voice_id, text, scene_num, base_url, speed=1.0, pitch=0):
    """Supertone APIë¥¼ ì‚¬ìš©í•´ TTS ì˜¤ë””ì˜¤ ìƒì„± ë° ì €ì¥"""
    
    # 1. í…ìŠ¤íŠ¸ ì •ê·œí™” (ìˆ«ì -> í•œê¸€)
    normalized_text = normalize_text_for_tts(text)

    # 2. ë§ˆì¹¨í‘œê°€ ìˆë“  ì—†ë“  ë¬´ì¡°ê±´ ë§ˆì¹¨í‘œ í•˜ë‚˜ ë” ì¶”ê°€í•˜ì—¬ í™•ì‹¤í•œ ëë§ºìŒ ìœ ë„
    normalized_text = normalized_text.strip() + "."

    base_url = base_url.rstrip('/')
    url = f"{base_url}/v1/text-to-speech/{voice_id}"
    
    headers = {
        "x-sup-api-key": api_key,
        "Content-Type": "application/json"
    }
    
    safe_text = normalized_text[:500] 
    
    payload = {
        "text": safe_text,
        "language": "ko",
        "model": "sona_speech_1",
        "voice_settings": {
            "speed": float(speed),
            "pitch_shift": int(pitch),
            "pitch_variance": 1
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, stream=True)
        
        if response.status_code == 200:
            filename = f"S{scene_num:03d}_audio.wav"
            full_path = os.path.join(AUDIO_OUTPUT_DIR, filename)
            
            # íŒŒì¼ ì €ì¥
            with open(full_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
            
            # [KEY FIX] ë§ˆì´í¬ë¡œ í˜ì´ë“œ (Micro-Fade): ë 30msë§Œ ì‚´ì§ ì¤„ì—¬ì„œ íŠ€ëŠ” ì†Œë¦¬ ì œê±°
            try:
                saved_audio = AudioSegment.from_wav(full_path)
                
                if len(saved_audio) > 100:
                    # 0.03ì´ˆ(30ms)ë§Œ í˜ì´ë“œ ì•„ì›ƒ -> ë§ëì€ ì‚´ë¦¬ê³ , ê¸°ê³„ìŒ 'í‹±' ì†Œë¦¬ë§Œ ì œê±°
                    saved_audio = saved_audio.fade_out(30)
                    saved_audio.export(full_path, format="wav")
            except Exception as e:
                print(f"Audio tail fix error: {e}")

            return full_path
        elif response.status_code == 404:
            return "VOICE_NOT_FOUND"
        else:
            return f"Error ({response.status_code}): {response.text}"
            
    except Exception as e:
        return f"System Error: {e}"

def smart_shorten_silence(file_path, max_allowed_silence_ms=300, min_silence_len=100, silence_thresh=-40):
    try:
        audio = AudioSegment.from_wav(file_path)
        silence_ranges = detect_silence(
            audio,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh
        )

        if not silence_ranges:
            return True, "ë¬´ìŒ êµ¬ê°„ ì—†ìŒ"

        output_audio = AudioSegment.empty()
        last_pos = 0

        for start, end in silence_ranges:
            output_audio += audio[last_pos:start]
            silence_duration = end - start
            if silence_duration > max_allowed_silence_ms:
                output_audio += AudioSegment.silent(duration=max_allowed_silence_ms)
            else:
                output_audio += audio[start:end]
            last_pos = end

        output_audio += audio[last_pos:]
        output_audio.export(file_path, format="wav")
        return True, "ì„±ê³µ"

    except Exception as e:
        return False, str(e)

def process_single_tts_task(api_key, voice_id, text, scene_num, base_url, speed, pitch, apply_silence_trim):
    audio_res = generate_supertone_tts(
        api_key, voice_id, text, scene_num, base_url, speed, pitch
    )
    if "Error" not in str(audio_res) and "VOICE_NOT_FOUND" not in str(audio_res):
        if apply_silence_trim:
            smart_shorten_silence(audio_res, max_allowed_silence_ms=300)
    return audio_res

# ==========================================
# [í•¨ìˆ˜] 5. ë¹„ë””ì˜¤ ìƒì„± (MoviePy - ê³ í™”ì§ˆ ì„¤ì •)
# ==========================================
def create_video_with_zoom(image_path, audio_path, output_dir, scene_num, is_zoom_in=True):
    """
    ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¥¼ í•©ì³ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì¤Œ íš¨ê³¼ ë¹„ë””ì˜¤ ìƒì„±.
    [ê³ í™”ì§ˆ ì„¤ì • ì ìš© ì™„ë£Œ]
    """
    try:
        output_filename = f"S{scene_num:03d}_video_zoom.mp4"
        output_path = os.path.join(output_dir, output_filename)
        
        audio_clip = AudioFileClip(audio_path)
        duration = audio_clip.duration
        
        original_pil = Image.open(image_path).convert("RGB")
        W, H = original_pil.size
        
        if W % 2 != 0: W -= 1
        if H % 2 != 0: H -= 1
        if original_pil.size != (W, H):
            original_pil = original_pil.resize((W, H), Image.LANCZOS)

        max_crop_ratio = 0.85 
        
        def effect(get_frame, t):
            progress = t / duration
            if is_zoom_in:
                current_ratio = 1.0 - (1.0 - max_crop_ratio) * progress
            else:
                current_ratio = max_crop_ratio + (1.0 - max_crop_ratio) * progress
            
            roi_w = W * current_ratio
            roi_h = H * current_ratio
            
            x0 = (W - roi_w) / 2
            y0 = (H - roi_h) / 2
            x1 = x0 + roi_w
            y1 = y0 + roi_h
            
            transformed_img = original_pil.transform(
                (W, H), 
                Image.EXTENT, 
                (x0, y0, x1, y1), 
                Image.BICUBIC 
            )
            return np.array(transformed_img)

        video = ImageClip(np.array(original_pil)).set_duration(duration).set_fps(30)
        video = video.fl(effect)
        video = video.set_audio(audio_clip)
        
        # [KEY FIX] ê³ í™”ì§ˆ ë Œë”ë§ ì„¤ì • (ë¹„íŠ¸ë ˆì´íŠ¸ 8000k, ì˜¤ë””ì˜¤ 192k, preset=slow)
        video.write_videofile(
            output_path, 
            codec="libx264", 
            audio_codec="aac", 
            bitrate="8000k",        # ì˜ìƒ í™”ì§ˆ ëŒ€í­ í–¥ìƒ
            audio_bitrate="192k",   # ì˜¤ë””ì˜¤ ìŒì§ˆ í–¥ìƒ
            preset="slow",          # ì¸ì½”ë”© í’ˆì§ˆ í–¥ìƒ (ì†ë„ëŠ” ì¡°ê¸ˆ ëŠë ¤ì§)
            logger=None
        )
        
        return output_path
        
    except Exception as e:
        return f"Error: {e}"

def process_single_video_task(item, output_dir, is_zoom_in):
    if item.get('audio_path') and os.path.exists(item['audio_path']):
        return create_video_with_zoom(
            item['path'], 
            item['audio_path'], 
            output_dir, 
            item['scene'], 
            is_zoom_in=is_zoom_in
        )
    return None

def merge_all_videos(video_paths, output_dir):
    try:
        clips = []
        for path in video_paths:
            if path and os.path.exists(path):
                clips.append(VideoFileClip(path))
        
        if not clips:
            return "No clips to merge"

        final_clip = concatenate_videoclips(clips, method="compose")
        final_output_path = os.path.join(output_dir, "FINAL_FULL_VIDEO.mp4")
        
        # [KEY FIX] ë³‘í•© ì‹œì—ë„ ê³ í™”ì§ˆ ìœ ì§€
        final_clip.write_videofile(
            final_output_path, 
            codec="libx264", 
            audio_codec="aac", 
            bitrate="8000k",
            audio_bitrate="192k",
            preset="slow",
            logger=None
        )
        return final_output_path
    except Exception as e:
        return f"Merge Error: {e}"

# ==========================================
# [UI] ì‚¬ì´ë“œë°” (ìë™ ë¡œê·¸ì¸ + ì¥ë¥´ ì„ íƒ ì ìš©)
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ í™˜ê²½ ì„¤ì •")
    
    # 1. Google API Key ìë™ ë¡œë“œ (secrets.toml í™œìš©)
    # .streamlit/secrets.toml íŒŒì¼ì— [general] google_api_key = "..." ê°€ ìˆìœ¼ë©´ ìë™ ë¡œë“œ
    if "general" in st.secrets and "google_api_key" in st.secrets["general"]:
        api_key = st.secrets["general"]["google_api_key"]
        st.success("ğŸ”‘ Google API Keyê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        api_key = st.text_input("ğŸ”‘ Google API Key", type="password", help="secrets.tomlì´ ì—†ìœ¼ë©´ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.")

    st.markdown("---")
    
    st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ ëª¨ë¸ ì„ íƒ")
    model_choice = st.radio("ì‚¬ìš©í•  AI ëª¨ë¸:", ("Premium (Gemini 3 Pro)", "Fast (Gemini-2.5-pro)"), index=0)
    
    if "Gemini 3 Pro" in model_choice:
        SELECTED_IMAGE_MODEL = "gemini-3-pro-image-preview" 
    else:
        SELECTED_IMAGE_MODEL = "gemini-2.5-pro"

    st.info(f"âœ… ì„ íƒ ëª¨ë¸: `{SELECTED_IMAGE_MODEL}`")
    
    st.markdown("---")
    st.subheader("â±ï¸ ì¥ë©´ ë¶„í•  ì„¤ì •")
    chunk_duration = st.slider("í•œ ì¥ë©´ë‹¹ ì§€ì† ì‹œê°„ (ì´ˆ)", 5, 60, 20, 5)
    chars_limit = chunk_duration * 8 
    
    st.markdown("---")
    
    # [NEW] ì¥ë¥´ ì„ íƒ ê¸°ëŠ¥ (í”„ë¡¬í”„íŠ¸ ë¶„ê¸°ìš©)
    st.subheader("ğŸ¨ ì˜ìƒ ì¥ë¥´(Mood) ì„¤ì •")
    genre_select = st.radio(
        "ì½˜í…ì¸  ì„±ê²© ì„ íƒ:",
        ("ë°ì€ ì •ë³´/ì´ìŠˆ (Bright & Flat)", "ì—­ì‚¬/ë‹¤í (Cinematic & Immersive)"),
        index=0,
        help="ì—­ì‚¬/ë‹¤í ì„ íƒ ì‹œ ì¡°ëª…ì´ ë” ë“œë¼ë§ˆí‹±í•´ì§€ê³  ë°°ê²½ ë¬˜ì‚¬ê°€ ê¹Šì–´ì§‘ë‹ˆë‹¤."
    )
    
    # ì„ íƒëœ ê°’ ë³€ìˆ˜ì— ì €ì¥ (ë©”ì¸ ë¡œì§ì—ì„œ ì‚¬ìš©)
    if "ë°ì€" in genre_select:
        SELECTED_GENRE_MODE = "info"
    else:
        SELECTED_GENRE_MODE = "history"

    st.markdown("---")

    # [NEW] ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ ì–¸ì–´ ì„ íƒ
    st.subheader("ğŸŒ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì–¸ì–´")
    target_language = st.selectbox(
        "ì´ë¯¸ì§€ ì†ì— ë“¤ì–´ê°ˆ ê¸€ì ì–¸ì–´:",
        ("Korean", "English", "Japanese"),
        index=0,
        help="ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ê°€ ì—°ì¶œë  ë•Œ ì–´ë–¤ ì–¸ì–´ë¡œ ì ì„ì§€ ì„ íƒí•©ë‹ˆë‹¤."
    )

    st.markdown("---")

    st.subheader("ğŸ–Œï¸ í™”í’(Style) ì§€ì¹¨")
    default_style = """
ëŒ€ì‚¬ì— ì–´ìš¸ë¦¬ëŠ” 2d ì–¼êµ´ì´ ë‘¥ê·¼ í•˜ì–€ìƒ‰ ìŠ¤í‹±ë§¨ ì—°ì¶œë¡œ ì„¤ëª…ê³¼ ì´í•´ê°€ ì˜ë˜ëŠ” í™”ë©´ ìë£Œ ëŠë‚Œìœ¼ë¡œ ê·¸ë ¤ì¤˜ ìƒí™©ì„ ì˜ ë‚˜íƒ€ë‚´ê²Œ ë¶„í™œí™”ë©´ìœ¼ë¡œ ë§ê³  í•˜ë‚˜ì˜ ì¥ë©´ìœ¼ë¡œ
ë„ˆë¬´ ì–´ì§€ëŸ½ì§€ ì•Šê²Œ, ê¸€ì”¨ëŠ” í•µì‹¬ í‚¤ì›Œë“œ 2~3ë§Œ ë‚˜ì˜¤ê²Œ í•œë‹¤
ê¸€ì”¨ê°€ ë„ˆë¬´ ë§ì§€ ì•Šê²Œ í•µì‹¬ë§Œ. 2D ìŠ¤í‹±ë§¨ì„ í™œìš©í•´ ëŒ€ë³¸ì„ ì„¤ëª…ì´ ì˜ë˜ê²Œ ì„¤ëª…í•˜ëŠ” ì—°ì¶œì„ í•œë‹¤. ìë§‰ ìŠ¤íƒ€ì¼ ì—°ì¶œì€ í•˜ì§€ ì•ŠëŠ”ë‹¤.
ê¸€ì”¨ê°€ ë‚˜ì˜¬ê²½ìš° í•µì‹¬ í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œë§Œ ë‚˜ì˜¤ê²Œ ë„ˆë¬´ ê¸€ì´ ë§ì§€ ì•Šë„ë¡ í•œë‹¤, ê¸€ìëŠ” ë°°ê²½ê³¼ ì„œë¬¼ì— ìì—°ìŠ¤ëŸ½ê²Œ ì—°ì¶œ, ì „ì²´ ë°°ê²½ ì—°ì¶œì€ 2Dë¡œ ë””í…Œì¼í•˜ê²Œ ëª°ì…ê° ìˆê²Œ ì—°ì¶œí•´ì„œ ê·¸ë ¤ì¤˜ (16:9)
ë‹¤ì–‘í•œ ì¥ì†Œì™€ ìƒí™© ì—°ì¶œë¡œ ë°°ê²½ì„ ë””í…Œì¼í•˜ê²Œ í•œë‹¤. ë¬´ì¡°ê±´ 2D ìŠ¤í‹±ë§¨ ì—°ì¶œ
    """
    style_instruction = st.text_area("AIì—ê²Œ ì§€ì‹œí•  ê·¸ë¦¼ ìŠ¤íƒ€ì¼", value=default_style.strip(), height=150)
    st.markdown("---")
    
    # [NEW] Supertone TTS ì„¤ì • (secrets.toml ì ìš©)
    st.subheader("ğŸ™ï¸ Supertone TTS ì„¤ì •")
    
    # Base URLì€ ë³´í†µ ì•ˆ ë°”ë€Œë¯€ë¡œ ê¸°ë³¸ê°’ ìœ ì§€
    supertone_base_url = st.text_input("API ì£¼ì†Œ (Base URL)", value=DEFAULT_SUPERTONE_URL)
    
    # API Key ìë™ ë¡œë“œ
    if "general" in st.secrets and "supertone_api_key" in st.secrets["general"]:
        supertone_api_key = st.secrets["general"]["supertone_api_key"]
        st.success("ğŸ”‘ Supertone API Keyê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        supertone_api_key = st.text_input("ğŸ”‘ Supertone API Key", type="password")
    
    # ëª©ì†Œë¦¬ ëª©ë¡ ê´€ë¦¬
    if 'supertone_voices' not in st.session_state:
        st.session_state['supertone_voices'] = []
    
    # ì—°ê²° í…ŒìŠ¤íŠ¸ ë²„íŠ¼
    if supertone_api_key:
        if st.button("ğŸ”Œ ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ëª©ì†Œë¦¬ ê°±ì‹ "):
            with st.spinner("ëª©ì†Œë¦¬ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì¤‘..."):
                success, voices, msg = check_connection_and_get_voices(supertone_api_key, supertone_base_url)
                if success:
                    st.session_state['supertone_voices'] = voices
                    st.success(f"{msg} ({len(voices)}ê°œ)")
                else:
                    st.error(msg)
                    st.session_state['supertone_voices'] = []
    
    # ëª©ì†Œë¦¬ ì„ íƒ UI
    available_voices = []
    selected_voice_id = ""
    
    if st.session_state['supertone_voices']:
        raw_list = st.session_state['supertone_voices']
        valid_voices = [v for v in raw_list if isinstance(v, dict) and 'name' in v and 'voice_id' in v]
        if valid_voices:
            voice_options = {f"{v['name']} ({v['voice_id']})": v['voice_id'] for v in valid_voices}
            selected_voice_label = st.selectbox("ëª©ì†Œë¦¬ ì„ íƒ", list(voice_options.keys()))
            selected_voice_id = voice_options[selected_voice_label]
            
            # ì¸ë„¤ì¼ í‘œì‹œ
            current_voice = next((v for v in valid_voices if v['voice_id'] == selected_voice_id), None)
            if current_voice and current_voice.get('thumbnail_image_url'):
                st.image(current_voice['thumbnail_image_url'], width=100)
    else:
        # ì—°ê²° ì•ˆ ë˜ì—ˆì„ ë•Œ ìˆ˜ë™ ì…ë ¥ì°½
        selected_voice_id = st.text_input("Voice ID ì§ì ‘ ì…ë ¥", value=DEFAULT_VOICE_ID)
    
    st.caption("TTS ì˜µì…˜")
    tts_speed = st.slider("ë§í•˜ê¸° ì†ë„", 0.5, 2.0, 1.0, 0.1)
    tts_pitch = st.slider("í”¼ì¹˜ ì¡°ì ˆ", -12, 12, 0, 1)

    st.markdown("---")
    max_workers = st.slider("ì‘ì—… ì†ë„(ë³‘ë ¬ ìˆ˜)", 1, 10, 5)

# ==========================================
# [UI] ë©”ì¸ í™”ë©´ 1: ëŒ€ë³¸ êµ¬ì¡°í™” ë° ìƒì„±
# ==========================================
st.title("ğŸ“º AI ìœ íŠœë¸Œ ëŒ€ë³¸ êµ¬ì¡° ë¶„ì„ê¸° (Pro)")
st.caption("êµ¬ì¡° ë¶„ì„ â¡ï¸ ë¡±í¼ ëŒ€ë³¸ ìƒì„±(ë³‘ë ¬ ì²˜ë¦¬) â¡ï¸ ì´ë¯¸ì§€ ìƒì„± â¡ï¸ TTS ì˜¤ë””ì˜¤ â¡ï¸ ë¹„ë””ì˜¤ ìƒì„±(Zoom íš¨ê³¼)")

# ì„¸ì…˜ ì´ˆê¸°í™”
if 'structured_content' not in st.session_state:
    st.session_state['structured_content'] = None
if 'section_scripts' not in st.session_state:
    st.session_state['section_scripts'] = {}
if 'video_title' not in st.session_state:
    st.session_state['video_title'] = ""
if 'user_initial_title' not in st.session_state:
    st.session_state['user_initial_title'] = ""

# 1. êµ¬ì¡° ë¶„ì„ ì„¹ì…˜
with st.container(border=True):
    user_title_input = st.text_input(
        "ğŸ“Œ ì˜ìƒ ì œëª© (ì„ íƒì‚¬í•­)", 
        placeholder="ì´ ì œëª©ì„ ì…ë ¥í•˜ë©´ ë‚˜ì¤‘ì— ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„ì—ì„œ ì´ì™€ ìœ ì‚¬í•œ ì œëª©ë“¤ì„ ì¶”ì²œë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        help="ë¹„ì›Œë‘ë©´ ëŒ€ë³¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ AIê°€ ì•Œì•„ì„œ ì œëª©ì„ ì¶”ì²œí•©ë‹ˆë‹¤."
    )

    raw_script = st.text_area("âœï¸ ë¶„ì„í•  ì›ê³ (ëŒ€ë³¸)ë¥¼ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:", height=200, placeholder="ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ì€...")
    analyze_btn = st.button("ğŸ” êµ¬ì¡° ë¶„ì„ ì‹¤í–‰", width="stretch", type="primary")

    if analyze_btn:
        if not api_key:
            st.error("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ Google API Keyë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not raw_script:
            st.warning("âš ï¸ ë¶„ì„í•  ëŒ€ë³¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.session_state['user_initial_title'] = user_title_input

            client = genai.Client(api_key=api_key)
            with st.status("ëŒ€ë³¸ ë‚´ìš© ë¶„ì„ ì¤‘...", expanded=True) as status:
                status.write(f"ğŸ§  Geminiê°€ ë‚´ìš©ì„ ì½ê³  êµ¬ì¡°ë¥¼ ì¡ê³  ìˆìŠµë‹ˆë‹¤...")
                result_text = generate_structure(client, raw_script)
                
                st.session_state['structured_content'] = result_text
                st.session_state['section_scripts'] = {} 

                import re
                match = re.search(r'^\s*1\.\s*\*\*(.*?)\*\*:\s*(.*)', result_text, re.MULTILINE)
                if match:
                    extracted = match.group(2).strip() if match.group(2).strip() else match.group(1).strip()
                    st.session_state['video_title'] = re.sub(r'\(.*?\)', '', extracted).strip()
                else:
                    st.session_state['video_title'] = user_title_input if user_title_input else "ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"

                status.update(label="âœ… ë¶„ì„ ì™„ë£Œ! ì œëª©ì´ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.", state="complete", expanded=False)

# 2. ëŒ€ë³¸ ìƒì„± ì„¹ì…˜
if st.session_state['structured_content']:
    st.divider()
    st.subheader("ğŸ“‘ ëŒ€ë³¸ êµ¬ì¡°í™” ê²°ê³¼")
    st.markdown(st.session_state['structured_content'])
    
    st.info(f"ğŸ“Œ **ì¶”ì¶œëœ ì˜ìƒ ì œëª©:** {st.session_state['video_title']} (ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„ì—ì„œ ìˆ˜ì • ê°€ëŠ¥)")

    st.divider()
    st.subheader("âš¡ ë¡±í¼ ëŒ€ë³¸ ì „ì²´ ì¼ê´„ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)")
    st.caption("ğŸš€ ë²„íŠ¼ í•œë²ˆìœ¼ë¡œ ëª¨ë“  ì±•í„°ë¥¼ ë™ì‹œì— ì‘ì„±í•©ë‹ˆë‹¤. (15ë¶„/20ë¶„/25ë¶„ ì˜µì…˜)")

    lines = st.session_state['structured_content'].split('\n')
    chapter_titles = ["Intro (ë„ì…ë¶€)"]
    found_chapters = re.findall(r'(?:Chapter|ì±•í„°)\s*\d+.*', st.session_state['structured_content'])
    seen = set()
    for ch in found_chapters:
        clean_ch = ch.replace('*', '').strip()
        if clean_ch not in seen:
            chapter_titles.append(clean_ch)
            seen.add(clean_ch)
    chapter_titles.append("Epilogue (ê²°ë¡ )")
    
    for title in chapter_titles:
        if title not in st.session_state['section_scripts']:
            st.session_state['section_scripts'][title] = ""

    with st.container(border=True):
        batch_instruction = st.text_area(
            "ğŸ“¢ ì „ì²´ ëŒ€ë³¸ ì‘ì„± ì§€ì¹¨ (ì„ íƒ ì‚¬í•­)", 
            placeholder="ì˜ˆ: ì•„ì£¼ ë¹„íŒì ì¸ ì–´ì¡°ë¡œ ì¨ì¤˜ / ì´ˆë“±í•™ìƒë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ë¹„ìœ ë¥¼ ë§ì´ ë“¤ì–´ì¤˜ / ë°˜ë§(í‰ì–´)ë¡œ ì‘ì„±í•´ì¤˜ ë“±",
            height=70
        )

        col_batch1, col_batch2 = st.columns([1, 1])
        with col_batch1:
            target_time = st.radio(
                "ğŸ¬ ì´ ì˜ìƒ ëª©í‘œ ì‹œê°„ (í…ìŠ¤íŠ¸ ë¶„ëŸ‰)",
                ("15ë¶„ (ì•½ 7,000ì)", "20ë¶„ (ì•½ 10,000ì)", "25ë¶„ (ì•½ 13,000ì)"),
                index=1
            )
            if "15ë¶„" in target_time: batch_duration_type = "2min" 
            elif "20ë¶„" in target_time: batch_duration_type = "3min" 
            else: batch_duration_type = "4min"

        with col_batch2:
            st.write("")
            st.write("") 
            st.write("") 
            batch_btn = st.button("ğŸš€ ì „ì²´ ëŒ€ë³¸ ë™ì‹œ ìƒì„± ì‹œì‘", type="primary", use_container_width=True)

    if batch_btn:
        if not api_key:
            st.error("âš ï¸ Google API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            client = genai.Client(api_key=api_key)
            status_box = st.status("ğŸš€ AIê°€ ì§€ì¹¨ì„ ë°˜ì˜í•˜ì—¬ ëª¨ë“  ì±•í„°ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤...", expanded=True)
            progress_bar = status_box.progress(0)
            
            total_tasks = len(chapter_titles)
            completed_tasks = 0
            
            with ThreadPoolExecutor(max_workers=10) as executor:
                future_to_title = {}
                for title in chapter_titles:
                    is_fixed = any(x in title for x in ["Intro", "Epilogue", "ë„ì…ë¶€", "ê²°ë¡ "])
                    current_duration = "fixed" if is_fixed else batch_duration_type
                    
                    future = executor.submit(
                        generate_section, 
                        client, 
                        title, 
                        st.session_state['structured_content'], 
                        current_duration, 
                        batch_instruction
                    )
                    future_to_title[future] = title
                
                for future in as_completed(future_to_title):
                    title = future_to_title[future]
                    try:
                        result_text = future.result()
                        st.session_state['section_scripts'][title] = result_text
                        st.session_state[f"txt_{title}"] = result_text 
                        completed_tasks += 1
                        progress_bar.progress(completed_tasks / total_tasks)
                        status_box.write(f"âœ… ì™„ë£Œ: {title}")
                    except Exception as e:
                        status_box.error(f"âŒ ì‹¤íŒ¨ ({title}): {e}")
            
            status_box.update(label="âœ¨ ì „ì²´ ìƒì„± ì™„ë£Œ! ì•„ë˜ì—ì„œ í™•ì¸í•˜ì„¸ìš”.", state="complete", expanded=False)
            time.sleep(1)
            st.rerun()

    st.subheader("ğŸ“ ì„¹ì…˜ë³„ í™•ì¸ ë° ìˆ˜ì •")
    full_combined_script = ""
    
    for title in chapter_titles:
        with st.expander(f"ğŸ“Œ {title}", expanded=False):
            is_intro_epilogue = any(x in title for x in ["Intro", "Epilogue", "ë„ì…ë¶€", "ê²°ë¡ "])
            
            if is_intro_epilogue:
                if st.button(f"ğŸ”„ {title} ë‹¤ì‹œ ìƒì„±", key=f"r_fix_{title}"):
                    client = genai.Client(api_key=api_key)
                    with st.spinner("ì¬ìƒì„± ì¤‘..."):
                        result = generate_section(client, title, st.session_state['structured_content'], "fixed")
                        st.session_state['section_scripts'][title] = result
                        st.session_state[f"txt_{title}"] = result 
                        st.rerun()
            else:
                c_cols = st.columns(3)
                def regen(dur):
                    client = genai.Client(api_key=api_key)
                    with st.spinner(f"{dur} ëª¨ë“œë¡œ ì¬ìƒì„± ì¤‘..."):
                        dur_code = "2min" if "2ë¶„" in dur else "3min" if "3ë¶„" in dur else "4min"
                        result = generate_section(client, title, st.session_state['structured_content'], dur_code)
                        st.session_state['section_scripts'][title] = result
                        st.session_state[f"txt_{title}"] = result
                        st.rerun()

                if c_cols[0].button("ğŸ”„ ë‹¤ì‹œ ìƒì„± (2ë¶„)", key=f"r2_{title}"): regen("2ë¶„")
                if c_cols[1].button("ğŸ”„ ë‹¤ì‹œ ìƒì„± (3ë¶„)", key=f"r3_{title}"): regen("3ë¶„")
                if c_cols[2].button("ğŸ”„ ë‹¤ì‹œ ìƒì„± (4ë¶„)", key=f"r4_{title}"): regen("4ë¶„")

            if f"txt_{title}" not in st.session_state:
                st.session_state[f"txt_{title}"] = st.session_state['section_scripts'].get(title, "")

            new_text = st.text_area(label="ğŸ“œ ëŒ€ë³¸ ë‚´ìš© (ìˆ˜ì • ê°€ëŠ¥)", height=300, key=f"txt_{title}")
            st.session_state['section_scripts'][title] = new_text
        
        if st.session_state['section_scripts'].get(title):
            full_combined_script += st.session_state['section_scripts'][title] + "\n\n"

    if full_combined_script:
        st.divider()
        st.subheader("ğŸ“¦ ìµœì¢… ì™„ì„± ëŒ€ë³¸")
        col_info, col_down = st.columns([3, 1])
        with col_info:
            st.caption(f"ğŸ“ ì´ ê¸€ì ìˆ˜: {len(full_combined_script)}ì (ê³µë°± í¬í•¨)")
        with col_down:
            st.download_button(label="ğŸ’¾ ëŒ€ë³¸ ë‹¤ìš´ë¡œë“œ (.txt)", data=full_combined_script, file_name="final_script.txt", mime="text/plain", use_container_width=True)
        st.text_area("ì•„ë˜ ë‚´ìš©ì„ ë³µì‚¬í•˜ê±°ë‚˜ ìœ„ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”", value=full_combined_script, height=500)

# ==========================================
# [ìˆ˜ì •ëœ UI] ë©”ì¸ í™”ë©´ 3: ì´ë¯¸ì§€ ìƒì„±
# ==========================================
st.divider()
st.title("ğŸ¬ AI ì”¬(ì¥ë©´) ìƒì„±ê¸° (Pro)")
st.caption(f"ì™„ì„±ëœ ëŒ€ë³¸ì„ ë„£ìœ¼ë©´ ì¥ë©´ë³„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. | ğŸ¨ Model: {SELECTED_IMAGE_MODEL}")

st.subheader("ğŸ“Œ ì „ì²´ ì˜ìƒ í…Œë§ˆ(ì œëª©) ì„¤ì •")
st.caption("ì´ë¯¸ì§€ ìƒì„± ì‹œ ì´ ì œëª©ì´ 'ì „ì²´ì ì¸ ë¶„ìœ„ê¸° ê¸°ì¤€'ì´ ë©ë‹ˆë‹¤.")

if 'video_title' not in st.session_state:
    st.session_state['video_title'] = ""
if 'title_candidates' not in st.session_state:
    st.session_state['title_candidates'] = []

col_title_input, col_title_btn = st.columns([4, 1])

# [ìˆ˜ì •ë¨] ë²„íŠ¼ ë¡œì§: êµ¬ì¡° ë¶„ì„ì´ ì—†ì–´ë„ ì œëª© ì…ë ¥ì´ ìˆìœ¼ë©´ ì‘ë™í•˜ë„ë¡ ë³€ê²½
with col_title_btn:
    st.write("") 
    st.write("") 
    if st.button("ğŸ’¡ ì œëª© 5ê°œ ì¶”ì²œ", help="ì…ë ¥í•œ í‚¤ì›Œë“œë‚˜ ëŒ€ë³¸ì„ ë°”íƒ•ìœ¼ë¡œ ì œëª©ì„ ì¶”ì²œí•©ë‹ˆë‹¤.", use_container_width=True):
        # í˜„ì¬ ì…ë ¥ëœ ì œëª©(ì£¼ì œ) ê°€ì ¸ì˜¤ê¸°
        current_user_title = st.session_state.get('video_title', "").strip()
        has_structure = st.session_state.get('structured_content')

        if not api_key:
            st.error("API Key í•„ìš”")
        # [í•µì‹¬ ìˆ˜ì •] êµ¬ì¡° ë¶„ì„ë„ ì•ˆ í–ˆê³ , ì œëª© ì…ë ¥ë„ ì—†ìœ¼ë©´ ê²½ê³ 
        elif not has_structure and not current_user_title:
            st.warning("âš ï¸ 'êµ¬ì¡° ë¶„ì„'ì„ ë¨¼ì € í•˜ê±°ë‚˜, ì™¼ìª½ì— 'ì£¼ì œ'ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            client = genai.Client(api_key=api_key)
            with st.spinner("AIê°€ ìµœì ì˜ ì œëª©ì„ ê³ ë¯¼ ì¤‘ì…ë‹ˆë‹¤..."):
                
                # 1. êµ¬ì¡° ë¶„ì„ ë°ì´í„°ëŠ” ì—†ì§€ë§Œ, ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì£¼ì œëŠ” ìˆëŠ” ê²½ìš°
                if current_user_title and not has_structure:
                    prompt_instruction = f"""
                    [Target Topic]
                    "{current_user_title}"
                    [Task]
                    Generate 5 click-bait YouTube video titles based on the Target Topic above.
                    ì‚¬ìš©ìê°€ ì…ë ¥í•œê±°ë‘ ìµœëŒ€í•œ ë¹„ìŠ·í•œ ì œëª©ìœ¼ë¡œ ì¶”ì²œ, 'ëª°ë½'ì´ ë“¤ì–´ê°„ ê²½ìš° ë§¨ ë’¤ì— ëª°ë½ìœ¼ë¡œ ëë‚˜ê²Œ í•œë‹¤.
                    """
                    context_data = "No script provided. Base it solely on the topic."

                # 2. êµ¬ì¡° ë¶„ì„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° (ì…ë ¥í•œ ì œëª©ì´ ìˆìœ¼ë©´ ê·¸ê²ƒë„ ë°˜ì˜)
                else:
                    if current_user_title:
                        prompt_instruction = f"""
                        [Target Context]
                        "{current_user_title}"
                        [Task]
                        Generate 5 variations of this title suitable for YouTube, considering the script below.
                        'ëª°ë½'ì´ ë“¤ì–´ê°„ ê²½ìš° ë§¨ ë’¤ì— ëª°ë½ìœ¼ë¡œ ëë‚˜ê²Œ í•œë‹¤.
                        """
                    else:
                        prompt_instruction = f"""
                        [Task]
                        Read the provided script structure and generate 5 catchy YouTube video titles in Korean.
                        """
                    context_data = st.session_state['structured_content']

                title_prompt = f"""
                [Role] You are a YouTube viral marketing expert.
                {prompt_instruction}
                
                [Script Context]
                {context_data}
                
                [Output Format]
                - Output ONLY the list of 5 titles.
                - No numbering (1., 2.), just 5 lines of text.
                - Language: Korean
                """
                
                try:
                    resp = client.models.generate_content(
                        model=GEMINI_TEXT_MODEL_NAME, 
                        contents=title_prompt
                    )
                    candidates = [line.strip() for line in resp.text.split('\n') if line.strip()]
                    clean_candidates = []
                    import re
                    for c in candidates:
                        clean = re.sub(r'^\d+\.\s*', '', c).replace('*', '').replace('"', '').strip()
                        if clean: clean_candidates.append(clean)
                    
                    st.session_state['title_candidates'] = clean_candidates[:5]
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

with col_title_input:
    st.text_input(
        "ì˜ìƒ ì œëª© (ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ ìš°ì¸¡ ë²„íŠ¼ìœ¼ë¡œ ì¶”ì²œë°›ìœ¼ì„¸ìš”)",
        key="video_title", 
        placeholder="ì œëª© í˜¹ì€ ë§Œë“¤ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë¶€ìë“¤ì˜ ìŠµê´€)"
    )

if st.session_state['title_candidates']:
    st.info("ğŸ‘‡ AIê°€ ì¶”ì²œí•œ ì œëª©ì…ë‹ˆë‹¤. í´ë¦­í•˜ë©´ ì ìš©ë©ë‹ˆë‹¤.")

    def apply_title(new_title):
        st.session_state['video_title'] = new_title
        st.session_state['title_candidates'] = [] 

    for idx, title in enumerate(st.session_state['title_candidates']):
        col_c1, col_c2 = st.columns([4, 1])
        with col_c1:
            st.markdown(f"**{idx+1}. {title}**")
        with col_c2:
            st.button(
                "âœ… ì„ íƒ", 
                key=f"sel_title_{idx}", 
                on_click=apply_title, 
                args=(title,), 
                use_container_width=True
            )
    
    if st.button("âŒ ëª©ë¡ ë‹«ê¸°"):
        st.session_state['title_candidates'] = []

if 'section_scripts' in st.session_state and st.session_state['section_scripts']:
    intro_text_acc = ""
    main_text_acc = ""
    for title_key, text in st.session_state['section_scripts'].items():
        if "Intro" in title_key or "ë„ì…ë¶€" in title_key:
            intro_text_acc += text + "\n\n"
        else:
            main_text_acc += text + "\n\n"
            
    st.write("ğŸ‘‡ **ìƒì„±ëœ ëŒ€ë³¸ ê°€ì ¸ì˜¤ê¸° (í´ë¦­ ì‹œ ì•„ë˜ ì…ë ¥ì°½ì— ì±„ì›Œì§‘ë‹ˆë‹¤)**")
    
    col_get1, col_get2 = st.columns(2)
    if "image_gen_input" not in st.session_state:
        st.session_state["image_gen_input"] = ""

    with col_get1:
        if st.button("ğŸ“¥ ì¸íŠ¸ë¡œ(Intro)ë§Œ ê°€ì ¸ì˜¤ê¸°", use_container_width=True):
            st.session_state["image_gen_input"] = intro_text_acc.strip()
            st.rerun()
    with col_get2:
        if st.button("ğŸ“¥ ë³¸ë¡ (Chapters) + ê²°ë¡ (Epilogue) ê°€ì ¸ì˜¤ê¸°", use_container_width=True):
            st.session_state["image_gen_input"] = main_text_acc.strip()
            st.rerun()

script_input = st.text_area(
    "ğŸ“œ ì´ë¯¸ì§€ë¡œ ë§Œë“¤ ëŒ€ë³¸ ì…ë ¥", 
    height=300, 
    placeholder="ìœ„ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€ë³¸ì„ ê°€ì ¸ì˜¤ê±°ë‚˜, ì§ì ‘ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...",
    key="image_gen_input"
)

if 'generated_results' not in st.session_state:
    st.session_state['generated_results'] = []
if 'is_processing' not in st.session_state:
    st.session_state['is_processing'] = False

# [KEY FIX] ë²„íŠ¼ í´ë¦­ ì‹œ ê²°ê³¼ë¬¼ ì´ˆê¸°í™” í•¨ìˆ˜ ì¶”ê°€
def clear_generated_results():
    st.session_state['generated_results'] = []

start_btn = st.button("ğŸš€ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘", type="primary", width="stretch", on_click=clear_generated_results)

if start_btn:
    if not api_key:
        st.error("âš ï¸ Google API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not script_input:
        st.warning("âš ï¸ ëŒ€ë³¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # [FIX] ê¸°ì¡´ ê²°ê³¼ í™•ì‹¤íˆ ë‚ ë¦¬ê¸°
        st.session_state['generated_results'] = [] 
        st.session_state['is_processing'] = True
        
        # [FIX] ê¸°ì¡´ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¬¼ë¦¬ì ìœ¼ë¡œ ì‚­ì œ (ì°Œêº¼ê¸° ì œê±°)
        if os.path.exists(IMAGE_OUTPUT_DIR):
            shutil.rmtree(IMAGE_OUTPUT_DIR) # í´ë” í†µì§¸ë¡œ ì‚­ì œ
        init_folders() # ë‹¤ì‹œ ê¹¨ë—í•œ í´ë” ìƒì„±
        
        client = genai.Client(api_key=api_key)
        
        status_box = st.status("ì‘ì—… ì§„í–‰ ì¤‘...", expanded=True)
        progress_bar = st.progress(0)
        
        # 1. ëŒ€ë³¸ ë¶„í• 
        status_box.write(f"âœ‚ï¸ ëŒ€ë³¸ ë¶„í•  ì¤‘...")
        chunks = split_script_by_time(script_input, chars_per_chunk=chars_limit)
        total_scenes = len(chunks)
        status_box.write(f"âœ… {total_scenes}ê°œ ì¥ë©´ìœ¼ë¡œ ë¶„í•  ì™„ë£Œ.")
        
        current_video_title = st.session_state.get('video_title', "").strip()
        if not current_video_title:
            current_video_title = "ì „ë°˜ì ì¸ ëŒ€ë³¸ ë¶„ìœ„ê¸°ì— ì–´ìš¸ë¦¬ëŠ” ë°°ê²½ (Context based on the script)"

        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„± (ë³‘ë ¬)
        status_box.write(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ì‘ì„± ì¤‘ ({GEMINI_TEXT_MODEL_NAME}) - ëª¨ë“œ: {SELECTED_GENRE_MODE}...") # (ì„ íƒ) ë¡œê·¸ ë©”ì‹œì§€ì— ëª¨ë“œ í‘œì‹œ ì¶”ê°€
        prompts = []
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = []
            
            for i, chunk in enumerate(chunks):
                # [ìˆ˜ì •] target_language ì¶”ê°€ ì „ë‹¬
                futures.append(executor.submit(
                    generate_prompt, 
                    api_key, 
                    i, 
                    chunk, 
                    style_instruction, 
                    current_video_title, 
                    SELECTED_GENRE_MODE,
                    target_language  # <--- [NEW] ì¶”ê°€ë¨
                ))
            
            for i, future in enumerate(as_completed(futures)):
                prompts.append(future.result())
                progress_bar.progress((i + 1) / (total_scenes * 2))
        
        prompts.sort(key=lambda x: x[0])
        
        # ... (ì´ì „ ì½”ë“œ: í”„ë¡¬í”„íŠ¸ ìƒì„± ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€) ...

        # 3. ì´ë¯¸ì§€ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ + ì†ë„ ì¡°ì ˆ)
        status_box.write(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ({SELECTED_IMAGE_MODEL})... (API ë³´í˜¸ë¥¼ ìœ„í•´ ì²œì²œíˆ ì§„í–‰ë©ë‹ˆë‹¤)")
        results = []
        
        # [ì¤‘ìš”] API ì œí•œì„ í”¼í•˜ê¸° ìœ„í•´ worker ìˆ˜ë¥¼ ê°•ì œë¡œ ì¡°ì ˆí•˜ê±°ë‚˜, ì œì¶œ ê°„ê²©ì„ ë‘¡ë‹ˆë‹¤.
        # ì‚¬ìš©ìê°€ ì„¤ì •í•œ max_workersë¥¼ ì“°ë˜, ìš”ì²­ ê°„ê²©ì„ ë²Œë¦½ë‹ˆë‹¤.
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_meta = {}
            for s_num, prompt_text in prompts:
                idx = s_num - 1
                orig_text = chunks[idx]
                fname = make_filename(s_num, orig_text)
                
                # [í•µì‹¬ ìˆ˜ì •] ìš”ì²­ì„ í•œêº¼ë²ˆì— ì˜ì§€ ì•Šê³  3ì´ˆì”© ì‰¬ë©´ì„œ ì œì¶œí•©ë‹ˆë‹¤.
                # ì´ë ‡ê²Œ í•˜ë©´ ë¶„ë‹¹ 20íšŒ ì œí•œ ì•ˆìª½ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë“¤ì–´ì˜µë‹ˆë‹¤.
                time.sleep(3) 
                
                future = executor.submit(generate_image, client, prompt_text, fname, IMAGE_OUTPUT_DIR, SELECTED_IMAGE_MODEL)
                future_to_meta[future] = (s_num, fname, orig_text, prompt_text)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            completed_cnt = 0
            for future in as_completed(future_to_meta):
                s_num, fname, orig_text, p_text = future_to_meta[future]
                path = future.result()
                
                # [í•µì‹¬] ì‹¤íŒ¨(None)í•˜ë”ë¼ë„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì—ëŠ” ë„£ì–´ì„œ ìˆœì„œê°€ ë°€ë¦¬ì§€ ì•Šê²Œ í•¨ (ì›í•œë‹¤ë©´ ì—ëŸ¬ ì´ë¯¸ì§€ ì²˜ë¦¬ ê°€ëŠ¥)
                if path:
                    results.append({
                        "scene": s_num,
                        "path": path,
                        "filename": fname,
                        "script": orig_text,
                        "prompt": p_text,
                        "audio_path": None,
                        "video_path": None 
                    })
                else:
                    # ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ë„˜ì–´ê°€ê±°ë‚˜, ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì„ ìˆ˜ë„ ìˆìŒ
                    st.error(f"Scene {s_num} ì´ë¯¸ì§€ ìƒì„± ìµœì¢… ì‹¤íŒ¨.")

                completed_cnt += 1
                progress_bar.progress(0.5 + (completed_cnt / total_scenes * 0.5))
        
        results.sort(key=lambda x: x['scene'])
        st.session_state['generated_results'] = results
        
        status_box.update(label="âœ… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", state="complete", expanded=False)
        st.session_state['is_processing'] = False
        
# ==========================================
# [ìˆ˜ì •ë¨] ê²°ê³¼ì°½ ë° ê°œë³„ ì¬ìƒì„± ê¸°ëŠ¥ ì¶”ê°€
# ==========================================
if st.session_state['generated_results']:
    st.divider()
    st.header(f"ğŸ“¸ ê²°ê³¼ë¬¼ ({len(st.session_state['generated_results'])}ì¥)")
    
    # ------------------------------------------------
    # 1. ì¼ê´„ ì‘ì—… ë²„íŠ¼ ì˜ì—­
    # ------------------------------------------------
    st.write("---")
    st.subheader("âš¡ ì›í´ë¦­ ì¼ê´„ ìƒì„± ì‘ì—…")
    
    c_btn1, c_btn2, c_btn3, c_btn4 = st.columns(4)
    
    with c_btn1:
        zip_data = create_zip_buffer(IMAGE_OUTPUT_DIR)
        st.download_button("ğŸ“¦ ì „ì²´ ì´ë¯¸ì§€ ZIP ë‹¤ìš´ë¡œë“œ", data=zip_data, file_name="all_images.zip", mime="application/zip", use_container_width=True)

    # TTS ì „ì²´ ìƒì„±
    with c_btn2:
        tts_batch_mode = st.selectbox("TTS ìƒì„± ëª¨ë“œ", ["ì›ë³¸ ìŒì„± ìƒì„±", "ë¬´ìŒ ì¡°ì ˆ ìŒì„± (ìµœëŒ€ 0.3ì´ˆ)"], help="ë¬´ìŒ ì¡°ì ˆ ì„ íƒ ì‹œ ê³µë°± ìë™ ì¶•ì†Œ")
        if st.button("ğŸ”Š TTS ì¼ê´„ ìƒì„±", use_container_width=True):
            if not supertone_api_key or not selected_voice_id:
                st.error("ì‚¬ì´ë“œë°”ì—ì„œ API Keyì™€ ëª©ì†Œë¦¬ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            else:
                # ì˜¤ë””ì˜¤ ë³€ê²½ ì‹œ í†µí•©ë³¸ ì‚­ì œ
                final_merged_file = os.path.join(VIDEO_OUTPUT_DIR, "FINAL_FULL_VIDEO.mp4")
                if os.path.exists(final_merged_file):
                    try: os.remove(final_merged_file)
                    except: pass

                status_box = st.status("ğŸ™ï¸ TTS ì¼ê´„ ìƒì„± ì¤‘...", expanded=True)
                progress_bar = status_box.progress(0)
                
                apply_trim = (tts_batch_mode == "ë¬´ìŒ ì¡°ì ˆ ìŒì„± (ìµœëŒ€ 0.3ì´ˆ)")
                total_files = len(st.session_state['generated_results'])
                completed_cnt = 0
                
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_idx = {}
                    for i, item in enumerate(st.session_state['generated_results']):
                        future = executor.submit(
                            process_single_tts_task, supertone_api_key, selected_voice_id, 
                            item['script'], item['scene'], supertone_base_url, 
                            tts_speed, tts_pitch, apply_trim
                        )
                        future_to_idx[future] = i
                    
                    for future in as_completed(future_to_idx):
                        idx = future_to_idx[future]
                        try:
                            result_path = future.result()
                            if "Error" not in str(result_path) and "VOICE_NOT_FOUND" not in str(result_path):
                                st.session_state['generated_results'][idx]['audio_path'] = result_path
                                st.session_state['generated_results'][idx]['video_path'] = None # ë¹„ë””ì˜¤ ë¦¬ì…‹
                            else:
                                st.write(f"âš ï¸ Scene {idx+1} ì˜¤ë¥˜: {result_path}")
                        except Exception as e:
                            st.write(f"âš ï¸ Scene {idx+1} ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
                        
                        completed_cnt += 1
                        progress_bar.progress(completed_cnt / total_files)
                
                status_box.update(label="âœ… TTS ìƒì„± ì™„ë£Œ!", state="complete", expanded=False)
                time.sleep(1)
                st.rerun()

    # ë¹„ë””ì˜¤ ì „ì²´ ìƒì„±
    with c_btn3:
        has_audio = any(item.get('audio_path') for item in st.session_state['generated_results'])
        if st.button("ğŸ¬ ë¹„ë””ì˜¤ ì „ì²´ ì¼ê´„ ìƒì„±", disabled=not has_audio, use_container_width=True):
            final_merged_file = os.path.join(VIDEO_OUTPUT_DIR, "FINAL_FULL_VIDEO.mp4")
            if os.path.exists(final_merged_file):
                try: os.remove(final_merged_file)
                except: pass
            
            status_box = st.status("ğŸ¬ ë¹„ë””ì˜¤ ë Œë”ë§ ì¤‘...", expanded=True)
            progress_bar = status_box.progress(0)
            
            total_files = len(st.session_state['generated_results'])
            completed_cnt = 0
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_idx = {}
                for i, item in enumerate(st.session_state['generated_results']):
                    is_zoom_in = (i % 2 == 0)
                    future = executor.submit(process_single_video_task, item, VIDEO_OUTPUT_DIR, is_zoom_in)
                    future_to_idx[future] = i
                
                for future in as_completed(future_to_idx):
                    idx = future_to_idx[future]
                    try:
                        vid_path = future.result()
                        if vid_path and "Error" not in vid_path:
                            st.session_state['generated_results'][idx]['video_path'] = vid_path
                        elif vid_path:
                            st.write(f"âš ï¸ Scene {idx+1} ë Œë”ë§ ì˜¤ë¥˜: {vid_path}")
                    except Exception as e:
                        st.write(f"âš ï¸ Scene {idx+1} ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
                    
                    completed_cnt += 1
                    progress_bar.progress(completed_cnt / total_files)
            
            status_box.update(label="âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!", state="complete", expanded=False)
            time.sleep(1)
            st.rerun()

    # ì „ì²´ ë³‘í•©
    with c_btn4:
        video_paths = [item.get('video_path') for item in st.session_state['generated_results'] if item.get('video_path')]
        final_path = os.path.join(VIDEO_OUTPUT_DIR, "FINAL_FULL_VIDEO.mp4")
        
        if video_paths:
            if st.button("ğŸï¸ ì „ì²´ ì˜ìƒ í•©ì¹˜ê¸° (ìƒˆë¡œê³ ì¹¨)", use_container_width=True):
                with st.spinner("ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ì¤‘..."):
                    if os.path.exists(final_path):
                        try: os.remove(final_path)
                        except: pass
                        
                    merged_result = merge_all_videos(video_paths, VIDEO_OUTPUT_DIR)
                    if "Error" in merged_result:
                        st.error(merged_result)
                    else:
                        st.success("ë³‘í•© ì™„ë£Œ!")
                        st.rerun()

            if os.path.exists(final_path):
                 with open(final_path, "rb") as f:
                    st.download_button("ğŸ’¾ ì „ì²´ ì˜ìƒ ë‹¤ìš´ë¡œë“œ (MP4)", data=f, file_name="final_video.mp4", mime="video/mp4", use_container_width=True)
        else:
            st.button("ğŸï¸ ì „ì²´ ì˜ìƒ í•©ì¹˜ê¸°", disabled=True, use_container_width=True)

    if not supertone_api_key or not selected_voice_id:
        st.warning("ğŸ™ï¸ Supertone TTS ì‚¬ìš©ì„ ìœ„í•´ API ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

    # ------------------------------------------------
    # 2. ê°œë³„ ë¦¬ìŠ¤íŠ¸ ë° [ì¬ìƒì„±] ê¸°ëŠ¥
    # ------------------------------------------------
    for index, item in enumerate(st.session_state['generated_results']):
        with st.container(border=True):
            cols = st.columns([1, 2])
            
            # [ì™¼ìª½] ì´ë¯¸ì§€ ë° ì¬ìƒì„± ë²„íŠ¼
            with cols[0]:
                try: st.image(item['path'], use_container_width=True)
                except: st.error("ì´ë¯¸ì§€ ì—†ìŒ")
                
                # [NEW] ì´ë¯¸ì§€ ê°œë³„ ì¬ìƒì„± ë²„íŠ¼
                if st.button(f"ğŸ”„ ì´ ì¥ë©´ë§Œ ì´ë¯¸ì§€ ë‹¤ì‹œ ìƒì„±", key=f"regen_img_{index}", use_container_width=True):
                    if not api_key:
                        st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    else:
                        with st.spinner(f"Scene {item['scene']} ë‹¤ì‹œ ê·¸ë¦¬ëŠ” ì¤‘..."):
                            client = genai.Client(api_key=api_key)
                            
                            # 1. í”„ë¡¬í”„íŠ¸ ë‹¤ì‹œ ìƒì„± (í˜„ì¬ ëŒ€ë³¸ê³¼ ìŠ¤íƒ€ì¼, ëª¨ë“œ ë°˜ì˜)
                            current_title = st.session_state.get('video_title', '')
                            # ëŒ€ë³¸ì´ ìˆ˜ì •ë˜ì—ˆì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ item['script'] ì‚¬ìš©
                            _, new_prompt = generate_prompt(
                                api_key, index, item['script'], style_instruction,
                                current_title, SELECTED_GENRE_MODE,
                                target_language # <--- [NEW] ì¶”ê°€ë¨
                            )
                            
                            # 2. ì´ë¯¸ì§€ ìƒì„±
                            new_path = generate_image(
                                client, new_prompt, item['filename'], 
                                IMAGE_OUTPUT_DIR, SELECTED_IMAGE_MODEL
                            )
                            
                            if new_path:
                                # 3. ê²°ê³¼ ì—…ë°ì´íŠ¸
                                st.session_state['generated_results'][index]['path'] = new_path
                                st.session_state['generated_results'][index]['prompt'] = new_prompt
                                # ì´ë¯¸ì§€ê°€ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ ê¸°ì¡´ ë¹„ë””ì˜¤ëŠ” ë¬´íš¨í™”
                                st.session_state['generated_results'][index]['video_path'] = None
                                st.success("ì´ë¯¸ì§€ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                time.sleep(0.5)
                                st.rerun()
                            else:
                                st.error("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            # [ì˜¤ë¥¸ìª½] ì •ë³´ ë° ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì»¨íŠ¸ë¡¤
            with cols[1]:
                st.subheader(f"Scene {item['scene']:02d}")
                st.caption(f"íŒŒì¼ëª…: {item['filename']}")
                
                # ëŒ€ë³¸ ìˆ˜ì • ê°€ëŠ¥í•˜ê²Œ í• ì§€? (í˜„ì¬ëŠ” displayë§Œ)
                st.write(f"**ëŒ€ë³¸:** {item['script']}")
                
                st.markdown("---")
                audio_col1, audio_col2 = st.columns([1, 3])
                
                # ì˜¤ë””ì˜¤ ë¡œì§
                if item.get('audio_path') and os.path.exists(item['audio_path']):
                    with audio_col1:
                        st.audio(item['audio_path'])
                        if st.button("ğŸ”„ ì˜¤ë””ì˜¤ ì¬ìƒì„±", key=f"re_tts_{item['scene']}"):
                             item['audio_path'] = None
                             item['video_path'] = None 
                             st.rerun()
                    
                    with audio_col2:
                        if item.get('video_path') and os.path.exists(item['video_path']):
                            st.video(item['video_path'])
                            with open(item['video_path'], "rb") as vf:
                                st.download_button("â¬‡ï¸ ë¹„ë””ì˜¤ ì €ì¥", data=vf, file_name=f"scene_{item['scene']}.mp4", mime="video/mp4", key=f"down_vid_{item['scene']}")
                        else:
                            is_zoom_in_mode = (index % 2 == 0)
                            button_label = f"ğŸ¬ ë¹„ë””ì˜¤ ìƒì„± ({'ì¤Œì¸' if is_zoom_in_mode else 'ì¤Œì•„ì›ƒ'})"

                            if st.button(button_label, key=f"gen_vid_{item['scene']}"):
                                with st.spinner("ë Œë”ë§ ì¤‘..."):
                                    vid_path = create_video_with_zoom(
                                        item['path'], item['audio_path'], VIDEO_OUTPUT_DIR, 
                                        item['scene'], is_zoom_in=is_zoom_in_mode
                                    )
                                    if "Error" in vid_path:
                                        st.error(vid_path)
                                    else:
                                        st.session_state['generated_results'][index]['video_path'] = vid_path
                                        st.rerun()
                else:
                    with audio_col1:
                        if st.button("ğŸ”Š TTS ìƒì„±", key=f"gen_tts_{item['scene']}"):
                            if not supertone_api_key or not selected_voice_id:
                                st.error("ì„¤ì • í•„ìš”")
                            else:
                                with st.spinner("ì˜¤ë””ì˜¤ ìƒì„± ì¤‘..."):
                                    audio_result = generate_supertone_tts(
                                        supertone_api_key, selected_voice_id, 
                                        item['script'], item['scene'], supertone_base_url, 
                                        speed=tts_speed, pitch=tts_pitch
                                    )
                                    if "Error" not in str(audio_result) and "VOICE_NOT_FOUND" != audio_result:
                                        st.session_state['generated_results'][index]['audio_path'] = audio_result
                                        st.rerun()
                                    else:
                                        st.error(audio_result)

                with st.expander("í”„ë¡¬í”„íŠ¸ í™•ì¸"):
                    st.text(item['prompt'])
                try:
                    with open(item['path'], "rb") as file:
                        st.download_button("â¬‡ï¸ ì´ë¯¸ì§€ ì €ì¥", data=file, file_name=item['filename'], mime="image/png", key=f"btn_down_{item['scene']}")
                except: pass




